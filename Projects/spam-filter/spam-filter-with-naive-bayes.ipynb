{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76675cb5",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "<img src=\"https://media.istockphoto.com/id/1323226102/photo/cyber-security-phishing-e-mail-network-security-computer-hacker-cloud-computing-ransomware.jpg?s=612x612&w=0&k=20&c=owkSqKKwVO94cN8WFmt4LA72cBb1kLVa8wguopJ8OhM=\" width=\"800\" height=\"100\">\n",
    "\n",
    "\n",
    "In this project, we'll be creating a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our objective is to design a program that accurately classifies new messages with over 80% precision, ensuring that more than 80% of the new messages are correctly categorized as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll be utilizing a dataset of 5,572 SMS messages that have already been manually classified by humans. This dataset was expertly curated by Tiago A. Almeida and José María Gómez Hidalgo and is available for download from [The UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/datasets?search=SMS%20Spam%20Collection). For more information on the data collection process and access to papers authored by Tiago A. Almeida and José María Gómez Hidalgo, please visit [this page](https://www.researchgate.net/publication/258514273_Towards_SMS_Spam_Filtering_Results_under_a_New_Dataset).\n",
    "\n",
    "## Exploring the Dataset\n",
    "\n",
    "To begin, we can read the `SMSSpamCollection` dataset using the `read_csv()` function from the `Pandas` package.\n",
    "\n",
    "It's important to note that the data points are separated by tabs, so we'll need to use the `sep='\\t'` parameter when calling the `read_csv()` function. Additionally, as the dataset lacks a header row, we need to use the `header=None` parameter to avoid the first row being incorrectly interpreted as the header row.\n",
    "\n",
    "Finally, to name the columns `Label` and `SMS`, we can use the `names=['Label', 'SMS']` parameter in our `read_csv()` function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80463799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Turn off the SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Read dataset\n",
    "sms_collection = pd.read_csv('SMSSpamCollection', sep='\\t', names=['Label', 'SMS'])\n",
    "\n",
    "# View first few rows\n",
    "sms_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4e543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5572\n",
      "Number of columns: 2\n"
     ]
    }
   ],
   "source": [
    "# Find number of rows and columns\n",
    "print(f'Number of rows: {sms_collection.shape[0]}')\n",
    "print(f'Number of columns: {sms_collection.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd521c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find percentage of messages label (spam and ham)\n",
    "round(sms_collection['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224fbee",
   "metadata": {},
   "source": [
    "Looking at the data, we can observe that approximately 87% of the messages are categorized as ham, with the remaining 13% being classified as spam. This sample appears to be a fair representation since, in reality, the majority of messages that individuals receive are typically ham.\n",
    "\n",
    "## Training and Test Set\n",
    "\n",
    "Before building our spam filter, it's important to think about how we'll test its effectiveness. This means designing a test before creating the software to avoid bias.\n",
    "\n",
    "To test our spam filter, we'll split our dataset into two categories: a training set and a test set.\n",
    "\n",
    "- The **training set** will have 80% of the dataset, which amounts to 4,458 messages.\n",
    "- The **test set** will have 20% of the dataset, which amounts to 1,114 messages.\n",
    "\n",
    "All 1,114 messages in our test set are already classified by a human. When the spam filter is ready, we'll treat these messages as new and have the filter classify them.\n",
    "\n",
    "Our goal is to create a spam filter that can classify new messages with an accuracy greater than 80%. We expect that more than 80% of the new messages will be classified correctly as spam or ham.\n",
    "\n",
    "To ensure that spam and ham messages are spread properly throughout the dataset, we'll randomize the entire dataset before creating the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bb11f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages in the training set: 4457\n",
      "Number of messages in the test set: 1115\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset and reset index\n",
    "data_randomized = sms_collection.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Calculate the training size\n",
    "training_size = int(len(data_randomized) * 0.8)\n",
    "\n",
    "# Split the dataset into training (80%) and test set (20%)\n",
    "training_set = data_randomized.iloc[:training_size]\n",
    "test_set = data_randomized.iloc[training_size:]\n",
    "\n",
    "# Verify the sizes of the training and test sets\n",
    "print(f'Number of messages in the training set: {len(training_set)}')\n",
    "print(f'Number of messages in the test set: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20266de6",
   "metadata": {},
   "source": [
    "Next, we'll calculate the percentages of spam and ham messages in both the training and test sets. We'll compare these percentages to the ones in the full dataset to see if they are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d1a087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(training_set['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6f9557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_set['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5caf9",
   "metadata": {},
   "source": [
    "The percentages in both the training and test set are similar to those in the full dataset, where the majority of messages are ham, accounting for about 87%, and the remaining 13% are spam. The obtained results confirm our expectations. With this done, we can proceed to cleaning the dataset.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "In the previous step, we divided our data into two sets: a training set and a test set. The next step is to use the training set to teach our algorithm how to classify new messages.\n",
    "\n",
    "When a new message arrives, the Naive Bayes algorithm uses the following two equations to classify it (note that \"Ham\" refers to \"non-spam\" in the second equation):\n",
    "\n",
    "$$P(Spam|w_1,w_2,...,w_n) \\propto P(Spam) \\cdot \\prod\\limits_{i=1}^{n} P(w_i|Spam)$$\n",
    "$$P(Ham|w_1,w_2,...,w_n) \\propto P(Ham) \\cdot \\prod\\limits_{i=1}^n P(w_i|Ham)$$\n",
    "\n",
    "To calculate the values for $P(wi|Spam)$ and $P(wi|Ham)$, we use these equations:\n",
    "\n",
    "$$P(w_i|Spam) = \\frac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha \\cdot N_{Vocabulary}}$$\n",
    "$$P(w_i|Ham) = \\frac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "Here's what the terms in the equations mean:\n",
    "\n",
    "$N_{w_i|Spam}$ = the number of times the word $w_i$ appears in spam messages\n",
    "\n",
    "$N_{w_i|Ham}$ = the number of times the word $w_i$ appears in non-spam messages\n",
    "\n",
    "$N_{Spam}$ = total number of words in spam messages\n",
    "\n",
    "$N_{Ham}$ = total number of words in non-spam messages\n",
    "\n",
    "$N_{Vocabulary}$ = total number of words in the vocabulary (vocabulary is the set of all unique words)\n",
    "\n",
    "$\\alpha$ = 1 ($\\alpha$ is a smoothing parameter)\n",
    "\n",
    "To calculate all these probabilities, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. Right now, our training and test sets have this format (the example messages are not real and are used for clarity):\n",
    "\n",
    "| Label | SMS |\n",
    "|-------|---------|\n",
    "| spam  | SECRET PRIZE! CLAIM SECRET PRIZE NOW!! |\n",
    "| ham   | Coming to my secret party? |\n",
    "| spam  | Winner! Claim secret prize now! |\n",
    "\n",
    "To make the calculations easier, we want bring the data to this format (the table below is a transformation of the table we see above):\n",
    "\n",
    "| Label | secret | prize | claim | now | coming | to  | my  | party | winner |\n",
    "|-------|--------|-------|-------|-----|--------|-----|-----|-------|--------|\n",
    "| spam  | 2    | 2    | 1    | 1   | 0      | 0   | 0   | 0     | 0     |\n",
    "| ham  | 1     | 0   | 0    | 0   | 1      | 1   | 1   | 1     | 0    |\n",
    "| spam   | 1     | 1    | 1   | 1   | 0      | 0   | 0   | 0     | 1     |\n",
    "\n",
    "About the transformation above, notice that:\n",
    "\n",
    "- The `SMS` column doesn't exist anymore.\n",
    "- Instead, the `SMS` column is replaced by a series of new columns, where each column represents a unique word from the vocabulary.\n",
    "- Each row describes a single message. For instance, the first row corresponds to the message \"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\", and it has the values `spam, 2, 2, 1, 1, 0, 0, 0, 0, 0`. These values tell us that:\n",
    "\n",
    "    - The message is spam.\n",
    "    - The word \"secret\" occurs two times inside the message.\n",
    "    - The word \"prize\" occurs two times inside the message.\n",
    "    - The word \"claim\" occurs one time inside the message.\n",
    "    - The word \"now\" occurs one time inside the message.\n",
    "    - The words \"coming\", \"to\", \"my\", \"party\", and \"winner\" occur zero times inside the message.\n",
    "\n",
    "- All words in the vocabulary are in lower case, so \"SECRET\" and \"secret\" come to be considered to be the same word.\n",
    "- Punctuation is not taken into account anymore (for instance, we can't look at the table and conclude that the first message initially had three exclamation marks).\n",
    "\n",
    "### Letter Case and Punctuation\n",
    "\n",
    "Let's begin the data cleaning process on the training set by removing the punctuation marks and converting all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93419895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ', regex=True).str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928dbc1",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "\n",
    "Our goal is to transform the training set into a table where each column represents a unique word in our **vocabulary**, and each row represents a message, with the values in each cell indicating the frequency of that word in that message. To do that, we first need to create a list of all the unique words in our training set, excluding the `Label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9e2af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List size before removing duplicates: 72423\n"
     ]
    }
   ],
   "source": [
    "# Split each message in the `SMS` column at the space character to transform it into a list\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "# List to store strings from 'SMS'\n",
    "vocabulary = []\n",
    "\n",
    "# Loop through the 'SMS' column and add each string to the list 'vocabulary'\n",
    "for str_list in training_set['SMS']:\n",
    "    for string in str_list:\n",
    "        vocabulary.append(string)\n",
    "        \n",
    "print(f'List size before removing duplicates: {len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a815b",
   "metadata": {},
   "source": [
    "We'll remove duplicates from the `vocabulary` list by transforming it into a set using the `set()` function. Then, we'll convert the resulting set back into a list using the `list()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821d2567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List size after removing duplicates: 7782\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(set(vocabulary))\n",
    "print(f'List size after removing duplicates: {len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c41c11",
   "metadata": {},
   "source": [
    "### The Final Training Set\n",
    "\n",
    "After creating the vocabulary for our training set messages, we will use it to transform the data to a format that helps us to count the frequency of each unique word in the messages.\n",
    "\n",
    "***From***: \n",
    "\n",
    "| Label | SMS |\n",
    "|-------|---------|\n",
    "| spam  | SECRET PRIZE! CLAIM SECRET PRIZE NOW!! |\n",
    "| ham   | Coming to my secret party? |\n",
    "| spam  | Winner! Claim secret prize now! |\n",
    "\n",
    "***To***:\n",
    "\n",
    "| Label | secret | prize | claim | now | coming | to  | my  | party | winner |\n",
    "|-------|--------|-------|-------|-----|--------|-----|-----|-------|--------|\n",
    "| spam  | 2    | 2    | 1    | 1   | 0      | 0   | 0   | 0     | 0     |\n",
    "| ham  | 1     | 0   | 0    | 0   | 1      | 1   | 1   | 1     | 0    |\n",
    "| spam   | 1     | 1    | 1   | 1   | 0      | 0   | 0   | 0     | 1     |\n",
    "\n",
    "Our end goal is to transform our training set into a new DataFrame that shows the frequency of each unique word in each message. However, before we do that, we need to build a dictionary that will hold this information. We'll then use this dictionary to create the DataFrame we need.\n",
    "\n",
    "For instance, to create the table we see above, we could use this dictionary and then convert it to a DataFrame:\n",
    "\n",
    "```python\n",
    "word_counts_per_sms = {'secret': [2,1,1],\n",
    "                       'prize': [2,0,1],\n",
    "                       'claim': [1,0,1],\n",
    "                       'now': [1,0,1],\n",
    "                       'coming': [0,1,0],\n",
    "                       'to': [0,1,0],\n",
    "                       'my': [0,1,0],\n",
    "                       'party': [0,1,0],\n",
    "                       'winner': [0,0,1]\n",
    "                      }\n",
    "\n",
    "\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()\n",
    "```\n",
    "\n",
    "|   | secret | prize | claim | now | coming | to | my | party | winner |\n",
    "|---|--------|-------|-------|-----|--------|----|----|-------|--------|\n",
    "| 0 | 2      | 2     | 1     | 1   | 0      | 0  | 0  | 0     | 0      |\n",
    "| 1 | 1      | 0     | 0     | 0   | 1      | 1  | 1  | 1     | 0      |\n",
    "| 2 | 1      | 1     | 1     | 1   | 0      | 0  | 0  | 0     | 1      |\n",
    "\n",
    "\n",
    "Note that the `Label` column is missing in the above table but we'll get to that later.\n",
    "\n",
    "To create the dictionary we need for our training set, we'll take the following steps:\n",
    "\n",
    "- We start by initializing a dictionary named `word_counts_per_sms`, where each key is a unique word (a string) from the **vocabulary**, and each value is a list of the length of training set, where each element in the list is a `0`.\n",
    "    - The code `[0] * 5` outputs `[0, 0, 0, 0, 0]`. So the code `[0] * len(training_set['SMS'])` outputs a list of the length of `training_set['SMS']`, where each element in the list will be a `0`.\n",
    "- We loop over `training_set['SMS']` using at the same time the [`enumerate()` function](https://docs.python.org/3/library/functions.html#enumerate) to get both the index and the SMS message (`index` and `sms`).\n",
    "    - Using a nested loop, we loop over `sms` (where `sms` is a list of strings, where each string represents a word in a message).\n",
    "        - We incremenent `word_counts_per_sms[word][index]` by `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab69b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1 # increment index number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a27dbb",
   "metadata": {},
   "source": [
    "Let's transform `word_counts_per_sms` into a DataFrame using `pd.DataFrame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89187349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wallet</th>\n",
       "      <th>invitation</th>\n",
       "      <th>cabin</th>\n",
       "      <th>enough</th>\n",
       "      <th>everyday</th>\n",
       "      <th>transfred</th>\n",
       "      <th>tmorrow</th>\n",
       "      <th>slide</th>\n",
       "      <th>studio</th>\n",
       "      <th>fondly</th>\n",
       "      <th>...</th>\n",
       "      <th>enufcredeit</th>\n",
       "      <th>give</th>\n",
       "      <th>steak</th>\n",
       "      <th>09064011000</th>\n",
       "      <th>snogs</th>\n",
       "      <th>gave</th>\n",
       "      <th>lift</th>\n",
       "      <th>eightish</th>\n",
       "      <th>celebrations</th>\n",
       "      <th>beg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wallet  invitation  cabin  enough  everyday  transfred  tmorrow  slide  \\\n",
       "0       0           0      0       0         0          0        0      0   \n",
       "1       0           0      0       0         0          0        0      0   \n",
       "2       0           0      0       0         0          0        0      0   \n",
       "3       0           0      0       0         0          0        0      0   \n",
       "4       0           0      0       0         0          0        0      0   \n",
       "\n",
       "   studio  fondly  ...  enufcredeit  give  steak  09064011000  snogs  gave  \\\n",
       "0       0       0  ...            0     0      0            0      0     0   \n",
       "1       0       0  ...            0     0      0            0      0     0   \n",
       "2       0       0  ...            0     0      0            0      0     0   \n",
       "3       0       0  ...            0     0      0            0      0     0   \n",
       "4       0       0  ...            0     0      0            0      0     0   \n",
       "\n",
       "   lift  eightish  celebrations  beg  \n",
       "0     0         0             0    0  \n",
       "1     0         0             0    0  \n",
       "2     0         0             0    0  \n",
       "3     0         0             0    0  \n",
       "4     0         0             0    0  \n",
       "\n",
       "[5 rows x 7782 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48889822",
   "metadata": {},
   "source": [
    "Concatenate the DataFrame containing the word counts with the DataFrame of the training set to get the `Label` and `SMS` columns as well using the [`pd.concat()` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f850253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>wallet</th>\n",
       "      <th>invitation</th>\n",
       "      <th>cabin</th>\n",
       "      <th>enough</th>\n",
       "      <th>everyday</th>\n",
       "      <th>transfred</th>\n",
       "      <th>tmorrow</th>\n",
       "      <th>slide</th>\n",
       "      <th>...</th>\n",
       "      <th>enufcredeit</th>\n",
       "      <th>give</th>\n",
       "      <th>steak</th>\n",
       "      <th>09064011000</th>\n",
       "      <th>snogs</th>\n",
       "      <th>gave</th>\n",
       "      <th>lift</th>\n",
       "      <th>eightish</th>\n",
       "      <th>celebrations</th>\n",
       "      <th>beg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  wallet  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0   \n",
       "2   ham                    [welp, apparently, he, retired]       0   \n",
       "3   ham                                           [havent]       0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0   \n",
       "\n",
       "   invitation  cabin  enough  everyday  transfred  tmorrow  slide  ...  \\\n",
       "0           0      0       0         0          0        0      0  ...   \n",
       "1           0      0       0         0          0        0      0  ...   \n",
       "2           0      0       0         0          0        0      0  ...   \n",
       "3           0      0       0         0          0        0      0  ...   \n",
       "4           0      0       0         0          0        0      0  ...   \n",
       "\n",
       "   enufcredeit  give  steak  09064011000  snogs  gave  lift  eightish  \\\n",
       "0            0     0      0            0      0     0     0         0   \n",
       "1            0     0      0            0      0     0     0         0   \n",
       "2            0     0      0            0      0     0     0         0   \n",
       "3            0     0      0            0      0     0     0         0   \n",
       "4            0     0      0            0      0     0     0         0   \n",
       "\n",
       "   celebrations  beg  \n",
       "0             0    0  \n",
       "1             0    0  \n",
       "2             0    0  \n",
       "3             0    0  \n",
       "4             0    0  \n",
       "\n",
       "[5 rows x 7784 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a5aaf",
   "metadata": {},
   "source": [
    "## Calculating Constants First\n",
    "\n",
    "To classify new messages as spam or ham, we need to calculate the probability values of two equations below:\n",
    "\n",
    "$$P(Spam|w_1,w_2,...,w_n) \\propto P(Spam) \\cdot \\prod\\limits_{i=1}^{n} P(w_i|Spam)$$\n",
    "$$P(Ham|w_1,w_2,...,w_n) \\propto P(Ham) \\cdot \\prod\\limits_{i=1}^n P(w_i|Ham)$$\n",
    "\n",
    "We'll use the following equations to calculate $P(w_i|Spam)$ and $P(w_i|Ham)$:\n",
    "\n",
    "$$P(w_i|Spam) = \\frac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha \\cdot N_{Vocabulary}}$$\n",
    "$$P(w_i|Ham) = \\frac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "\n",
    "- $P(Spam)$ and $P(Ham)$\n",
    "- $N_{Spam}$, $N_{Ham}$, $N_{Vocabulary}$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $N_{Spam}$ is equal to the number of words in all the spam messages.\n",
    "- $N_{Ham}$ is equal to the number of words in all the non-spam messages.\n",
    "- $N_{Vocabulary}$ is equal to the total number of unique words in the training set.\n",
    "\n",
    "We'll also use Laplace smoothing and set $\\alpha$ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf250d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with spam and ham messages\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# Calculate probability of spam and ham in the training set\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# Calculate number of words in spam, ham, and vocabulary\n",
    "n_spam = spam_messages['SMS'].apply(len).sum()\n",
    "n_ham = ham_messages['SMS'].apply(len).sum()\n",
    "\n",
    "# Calculate total number of unique words in the training set\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Set Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645f9f8",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "Once we have the constant terms calculated above, we can calculate the parameters $P(w_i|Spam)$ and $P(w_i|Ham)$ using the following formulas. Each parameter is a conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "$$P(w_i|Spam) = \\frac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "$$P(w_i|Ham) = \\frac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha \\cdot N_{Vocabulary}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2ba610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59352e5f",
   "metadata": {},
   "source": [
    "## Classifying A New Message\n",
    "\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message $(w_1, w_2, ..., w_n)$\n",
    "- Calculates $P(Spam|w_1, w_2, ..., w_n)$ and $P(Ham|w_1, w_2, ..., w_n)$\n",
    "- Compares the values of $P(Spam|w_1, w_2, ..., w_n)$ and $P(Ham|w_1, w_2, ..., w_n)$, and:\n",
    "    - If $P(Ham|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as ham.\n",
    "    - If $P(Ham|w_1, w_2, ..., w_n) < P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as spam.\n",
    "    - If $P(Ham|w_1, w_2, ..., w_n) = P(Spam|w_1, w_2, ..., w_n)$, then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c8e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    \"\"\"\n",
    "    Classify a given message as \"Spam\" or \"Ham\" using a Naive Bayes algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    message : str\n",
    "        The message to be classified.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        This function only prints the label assigned to the message.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> classify(\"Urgent! Call now to claim your prize!\")\n",
    "    P(Spam|message): 0.999\n",
    "    P(Ham|message): 0.001\n",
    "    Label: Spam\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "        if word not in parameters_spam and word not in parameters_ham:\n",
    "            pass\n",
    "    \n",
    "    print(f'P(Spam|message): {p_spam_given_message}')\n",
    "    print(f'P(Ham|message): {p_ham_given_message}')\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09636c",
   "metadata": {},
   "source": [
    "We can test the `classify()` function by passing two new messages as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1abd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3489598779101096e-25\n",
      "P(Ham|message): 1.9380782419077522e-27\n",
      "Label: Spam\n",
      "\n",
      "P(Spam|message): 2.4385273359614485e-25\n",
      "P(Ham|message): 3.6893872875947e-21\n",
      "Label: Ham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_msgs = ['WINNER!! This is the secret code to unlock the money: C3421.', 'Sounds good, Tom, then see u there']\n",
    "\n",
    "for msg in test_msgs:\n",
    "    classify(msg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadfe81",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy\n",
    "\n",
    "In the previous section, we developed a spam filter and used it to classify two new messages. In the following step, we will evaluate the performance of our spam filter on a test set containing 1,115 messages. We will compare the output classification labels generated by the algorithm to the actual labels provided by humans. It is worth noting that during training, our algorithm was not exposed to these 1,115 messages, making every message in the test set novel from the algorithm's perspective.\n",
    "\n",
    "To begin with, we need to modify the `classify()` function that we created earlier to return the labels instead of printing them. As shown below, the `return` statements replace the `print()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c28bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "        if word not in parameters_spam and word not in parameters_ham:\n",
    "            pass\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b8786",
   "metadata": {},
   "source": [
    "Now that we have a function that returns labels instead of printing them, we can use it to create a new column in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c68a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wherre's my boytoy ? :-(</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "4457   ham                           Wherre's my boytoy ? :-(       ham\n",
       "4458   ham          Later i guess. I needa do mcat study too.       ham\n",
       "4459   ham             But i haf enuff space got like 4 mb...       ham\n",
       "4460  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "4461   ham  All sounds good. Fingers . Makes it difficult ...       ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a283fe",
   "metadata": {},
   "source": [
    "Now we can compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages. To make the measurement, we'll use **accuracy** as a metric:\n",
    "\n",
    "$$\\text{Accuracy}=\\frac{\\text{number of correctly classified messages}}{\\text{total number of classified messages}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5c0a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1101\n",
      "Incorrect: 14\n",
      "Accuracy: 98.74\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for index, row in test_set.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print(f'Correct: {correct}')\n",
    "print(f'Incorrect: {total - correct}')\n",
    "print(f'Accuracy: {round(correct/total*100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011b958",
   "metadata": {},
   "source": [
    "Our spam filter achieved an accuracy of 98.74%, which is quite impressive. Out of the 1,115 messages in the test set, the filter correctly classified 1,101 of them.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In conclusion, this project successfully implemented a spam filter using the multinomial Naive Bayes algorithm and a dataset of 5,572 labeled SMS messages. The filter is capable of classifying a new message as either spam or ham with high accuracy, achieving a rate of 98.74%, which is significantly better than our initial target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
